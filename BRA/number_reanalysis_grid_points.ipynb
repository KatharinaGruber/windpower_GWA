{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from paths_bra import *\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare turbine location data\n"
     ]
    }
   ],
   "source": [
    "# MERRA-2 and ERA5 only unique interpolated locations\n",
    "print('prepare turbine location data')\n",
    "# open turbine files\n",
    "wt_mer = pd.read_csv(bra_path + '/turbine_data_mer.csv', index_col=0)\n",
    "wt_era = pd.read_csv(bra_path + '/turbine_data_era.csv', index_col=0)\n",
    "\n",
    "# open wind files\n",
    "wind_mer = xr.open_mfdataset(mer_path + \"/eff_ws/merra2_wind_BRA_*.nc\", chunks = {'time': 38})\n",
    "alpha_mer = xr.open_mfdataset(mer_path + \"/eff_ws/merra2_alpha_BRA_*.nc\", chunks = {'time': 38})\n",
    "wind_era = xr.open_mfdataset(era_path + \"/eff_ws/era5_wind_BRA_*.nc\", chunks = {'time': 38})\n",
    "alpha_era = xr.open_mfdataset(era_path + \"/eff_ws/era5_alpha_BRA_*.nc\", chunks = {'time': 38})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.1s\n",
      "[########################################] | 100% Completed |  0.1s\n",
      "[########################################] | 100% Completed |  0.1s\n",
      "[########################################] | 100% Completed |  0.1s\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe with sequence the size of MERRA-2 grid to find out which turbines interpolate to the same point\n",
    "in_seq_mer = xr.Dataset({'x':(['lat','lon'],\n",
    "                              np.array(range(wind_mer.wh50.isel(time=0).values.size)).reshape(wind_mer.wh50.isel(time=0).values.shape))},\n",
    "                         coords = {'lat':wind_mer.lat.values,\n",
    "                                   'lon':wind_mer.lon.values})\n",
    "in_seq_era = xr.Dataset({'x':(['lat','lon'],\n",
    "                              np.array(range(wind_era.wh100.isel(time=0).values.size)).reshape(wind_era.wh100.isel(time=0).values.shape))},\n",
    "                         coords = {'lat':wind_era.latitude.values,\n",
    "                                   'lon':wind_era.longitude.values})\n",
    "\n",
    "# interpolate to reanalysis grid points\n",
    "ip_mer = in_seq_mer.interp(coords={\"lon\":xr.DataArray(wt_mer.lon,dims='location'),\n",
    "                                   \"lat\":xr.DataArray(wt_mer.lat,dims='location')},method=\"nearest\").to_dataframe()\n",
    "ip_era = in_seq_era.interp(coords={\"lon\":xr.DataArray(wt_era.lon,dims='location'),\n",
    "                                   \"lat\":xr.DataArray(wt_era.lat,dims='location')},method=\"nearest\").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique locations\n",
    "uniques_mer = ip_mer.groupby(ip_mer.x).min()\n",
    "uniques_era = ip_era.groupby(ip_era.x).min()\n",
    "\n",
    "# add ids to unique locations\n",
    "uniques_era['cor_id'] = range(len(uniques_era.index))\n",
    "uniques_mer['cor_id'] = range(len(uniques_mer.index))\n",
    "\n",
    "# add ids to wind turbine data\n",
    "wt_mer['cor_id'] = ip_mer.x.map(uniques_mer.cor_id)\n",
    "wt_era['cor_id'] = ip_era.x.map(uniques_era.cor_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANL = pd.read_csv(bra_path + '/turbine_data.csv', index_col = 0)\n",
    "lbl = pd.read_csv(bra_path+ '/labels_turbine_data_gwa3.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# usinas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some locations have more than one park, get shares of parks\n",
    "sharesMER = ANL.cap.groupby([lbl.lbl_mer.values,ANL.name.values]).sum()/ANL.cap.groupby([lbl.lbl_mer.values,ANL.name.values]).sum().index.get_level_values(0).map(ANL.cap.groupby(lbl.lbl_mer.values).sum())\n",
    "sharesERA = ANL.cap.groupby([lbl.lbl_era.values,ANL.name.values]).sum()/ANL.cap.groupby([lbl.lbl_era.values,ANL.name.values]).sum().index.get_level_values(0).map(ANL.cap.groupby(lbl.lbl_era.values).sum())\n",
    "sharesMERg = ANL.cap.groupby([lbl.lbl_mer_gwa.values,ANL.name.values]).sum()/ANL.cap.groupby([lbl.lbl_mer_gwa.values,ANL.name.values]).sum().index.get_level_values(0).map(ANL.cap.groupby(lbl.lbl_mer_gwa.values).sum())\n",
    "sharesERAg = ANL.cap.groupby([lbl.lbl_era_gwa.values,ANL.name.values]).sum()/ANL.cap.groupby([lbl.lbl_era_gwa.values,ANL.name.values]).sum().index.get_level_values(0).map(ANL.cap.groupby(lbl.lbl_era_gwa.values).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ids to shares\n",
    "sharesMER = pd.DataFrame({'share':sharesMER,\n",
    "                          'cor_id':sharesMER.index.get_level_values(0).map(pd.Series(wt_mer.cor_id.values,index=lbl.lbl_mer.unique()))})\n",
    "sharesERA = pd.DataFrame({'share':sharesERA,\n",
    "                          'cor_id':sharesERA.index.get_level_values(0).map(pd.Series(wt_era.cor_id.values,index=lbl.lbl_era.unique()))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group ids by park\n",
    "cidMER = sharesMER.groupby(sharesMER.index.get_level_values(1)).cor_id.unique()\n",
    "cidERA = sharesERA.groupby(sharesERA.index.get_level_values(1)).cor_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of grid cells\n",
    "ngc_USI_mer = cidMER.apply(len)\n",
    "ngc_USI_era = cidERA.apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load matching parks\n",
    "mpH = pd.read_pickle(bra_path + '/matches2Hlc.pkl')\n",
    "mpH100 = mpH[mpH.score==100].drop('score',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngc_EST_mer = ngc_USI_mer[mpH100.ANL_name].groupby(mpH100.state.values).sum()\n",
    "ngc_EST_era = ngc_USI_era[mpH100.ANL_name].groupby(mpH100.state.values).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brazil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngc_BRA_mer = pd.Series(ngc_EST_mer.sum(), index=['BRA'])\n",
    "ngc_BRA_era = pd.Series(ngc_EST_era.sum(), index=['BRA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge all sizes\n"
     ]
    }
   ],
   "source": [
    "# merge sizes\n",
    "print('merge all sizes')\n",
    "# merge sizes per scale\n",
    "ngc_USI = pd.concat([pd.DataFrame({'scale':'park',\n",
    "                                   'region':ngc_USI_mer.index,\n",
    "                                   'dataset':'MERRA2',\n",
    "                                   'cor':ngc_USI_mer.values}),\n",
    "                     pd.DataFrame({'scale':'park',\n",
    "                                   'region':ngc_USI_era.index,\n",
    "                                   'dataset':'ERA5',\n",
    "                                   'cor':ngc_USI_era.values})])\n",
    "\n",
    "ngc_EST = pd.concat([pd.DataFrame({'scale':'state',\n",
    "                                   'region':ngc_EST_mer.index,\n",
    "                                   'dataset':'MERRA2',\n",
    "                                   'cor':ngc_EST_mer.values}),\n",
    "                     pd.DataFrame({'scale':'state',\n",
    "                                   'region':ngc_EST_era.index,\n",
    "                                   'dataset':'ERA5',\n",
    "                                   'cor':ngc_EST_era.values})])\n",
    "\n",
    "ngc_BRA = pd.concat([pd.DataFrame({'scale':'country',\n",
    "                                   'region':ngc_BRA_mer.index,\n",
    "                                   'dataset':'MERRA2',\n",
    "                                   'cor':ngc_BRA_mer.values}),\n",
    "                     pd.DataFrame({'scale':'country',\n",
    "                                   'region':ngc_BRA_era.index,\n",
    "                                   'dataset':'ERA5',\n",
    "                                   'cor':ngc_BRA_era.values})])\n",
    "# merge all scales\n",
    "ngc = pd.concat([ngc_USI,ngc_EST,ngc_BRA]*3, axis=0)\n",
    "# add temp column (sizes are the same for all)\n",
    "ngc['temp'] = np.repeat(['m','d','h'],len(ngc)/3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save system sizes\n"
     ]
    }
   ],
   "source": [
    "# save system sizes calcualted by number of grid points\n",
    "print('save system sizes')\n",
    "ngc.to_csv(results_path + '/number_grid_points.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py37]",
   "language": "python",
   "name": "conda-env-.conda-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
